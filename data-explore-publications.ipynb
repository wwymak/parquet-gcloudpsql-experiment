{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 as pg\n",
    "import io\n",
    "\n",
    "import config\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of files in the bucket, so rather than trying to load everything at once, download a few files to check out, figure out what data cleaning needs to be done,( and how to use parquet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using fastparquet to convert to dataframe\n",
    "test_data_file = './data/sample-data/2017-06-18/part-00099-6327ce66-f2d7-4bb6-b570-cc0db41e26e6.snappy.parquet'\n",
    "pfile = fastparquet.ParquetFile(test_data_file)\n",
    "df = pfile.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>channel</th>\n",
       "      <th>pageType</th>\n",
       "      <th>platform</th>\n",
       "      <th>publicationId</th>\n",
       "      <th>url</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10639315</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:poll|sim</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/transfe...</td>\n",
       "      <td>4f32564a-0503-4a8f-91ca-c980a7636d15</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10638305</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:vid|bc:readmore:readmore:readmore</td>\n",
       "      <td>nationals</td>\n",
       "      <td>4</td>\n",
       "      <td>http://www.dailyrecord.co.uk/news/uk-world-new...</td>\n",
       "      <td>ddb98cc7-086f-4fe0-8406-9eb0072324e4</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10636511</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:readmore:poll|sim:vid|bc</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/news/ar...</td>\n",
       "      <td>b3d3e81b-c8c2-4533-a4a4-cea2892873e9</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4388389</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:vid|bc:poll|sim</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/ampp3d/cats-9-liv...</td>\n",
       "      <td>876dca7b-d04f-4fe6-a51e-a1f909ec32b2</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10640509</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/uk-news/google-me...</td>\n",
       "      <td>4961660a-c1cb-400a-ae8e-127877b431a5</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleId channel                                        pageType  \\\n",
       "0   10639315   sport                  article:news:readmore:poll|sim   \n",
       "1   10638305    news  article:news:vid|bc:readmore:readmore:readmore   \n",
       "2   10636511   sport  article:news:readmore:readmore:poll|sim:vid|bc   \n",
       "3    4388389    news                    article:news:vid|bc:poll|sim   \n",
       "4   10640509    news                                    article:news   \n",
       "\n",
       "    platform  publicationId  \\\n",
       "0  nationals              2   \n",
       "1  nationals              4   \n",
       "2  nationals              2   \n",
       "3  nationals              2   \n",
       "4  nationals              2   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.mirror.co.uk/sport/football/transfe...   \n",
       "1  http://www.dailyrecord.co.uk/news/uk-world-new...   \n",
       "2  http://www.mirror.co.uk/sport/football/news/ar...   \n",
       "3  http://www.mirror.co.uk/news/ampp3d/cats-9-liv...   \n",
       "4  http://www.mirror.co.uk/news/uk-news/google-me...   \n",
       "\n",
       "                                 userId           timestamp  \n",
       "0  4f32564a-0503-4a8f-91ca-c980a7636d15 2017-06-18 02:31:02  \n",
       "1  ddb98cc7-086f-4fe0-8406-9eb0072324e4 2017-06-18 02:31:02  \n",
       "2  b3d3e81b-c8c2-4533-a4a4-cea2892873e9 2017-06-18 02:31:02  \n",
       "3  876dca7b-d04f-4fe6-a51e-a1f909ec32b2 2017-06-18 02:31:02  \n",
       "4  4961660a-c1cb-400a-ae8e-127877b431a5 2017-06-18 02:31:02  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get a quick view of what data is there\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data looks fairly clean, but quick check to see if thee are any missing valeus:\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is to get a feel for what sort of data there are in the different fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         22103\n",
       "unique            3\n",
       "top       nationals\n",
       "freq          16270\n",
       "Name: platform, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the differnt platforms the publications has?\n",
    "df['platform'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nationals    16270\n",
       "regionals     5577\n",
       "ronionals      256\n",
       "Name: platform, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news                    9276\n",
       "sport                   6499\n",
       "3am                     3213\n",
       "tv                      1237\n",
       "whats-on                 524\n",
       "lifestyle                410\n",
       "science                  178\n",
       "money                    172\n",
       "tech                     141\n",
       "arsenal-fc                73\n",
       "showbiz                   66\n",
       "chelsea-fc                54\n",
       "entertainment             46\n",
       "tottenham-hotspur-fc      46\n",
       "ece_incoming              36\n",
       "scotland-now              35\n",
       "business                  29\n",
       "play                      21\n",
       "west-ham-united-fc        15\n",
       "crystal-palace-fc         14\n",
       "usvsth3m                   4\n",
       "in-your-area               4\n",
       "opinion                    2\n",
       "special-features           2\n",
       "home                       2\n",
       "features                   1\n",
       "config                     1\n",
       "homes-and-property         1\n",
       "motoring                   1\n",
       "Name: channel, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Channels: a lot of news as expected, and a lot of football...?\n",
    "df['channel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "# hmm, so what are ronionals...? could it be a typp?\n",
    "roinials = [x for x in df['platform'] if x == 'ronionals']\n",
    "print(len(roinials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "however, there is enough of them that it doesn't seem to be the case, and further clarification from the dataset told me that there are actually something called 'ronionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.tslib.Timestamp"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the timestamp column is obvious in what it means, but useful to check that it is indeed read as timestamp, \n",
    "# and yes it is\n",
    "type(df['timestamp'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the range of times, although this is likely to be different -- eg during waking hours there are \n",
    "more visits etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-06-18 02:21:01')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-06-18 04:39:01')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "to have a unique id for publication and articles can help to look  comparisions between articles publications etc, \n",
    "and a quick look at the publicationId shows that different publications (from their urls) share the same publicationId. \n",
    "\n",
    "After a bit of clarification, the unique id for a publication is 'platform' + 'publicationId', and that for an article is 'platform' + 'articleId' -- so create those columns in the df\n",
    "\n",
    "Also, the url can be split into 'host' and the last item in the path, which gives names to what the publication actually is and what is the article name-- would make a lot more sense to whoever is seeing the stats than ids, so extract those too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_name(url):\n",
    "        path_arr = urlparse(url).path.split('/')\n",
    "        return path_arr[len(path_arr) -1]\n",
    "df['publicationSite'] = df['url'].apply(lambda x: urlparse(x).hostname)\n",
    "df['articleUrlName'] = df['url'].apply(lambda x: get_article_name(x))\n",
    "df['uniquePublicationId'] = df['platform'] + '-' + df['publicationId'].astype(str)\n",
    "df['uniqueArticleId'] = df['platform'] + '-' + df['articleId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>channel</th>\n",
       "      <th>pageType</th>\n",
       "      <th>platform</th>\n",
       "      <th>publicationId</th>\n",
       "      <th>url</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>publicationSite</th>\n",
       "      <th>articleUrlName</th>\n",
       "      <th>uniquePublicationId</th>\n",
       "      <th>uniqueArticleId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10639315</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:poll|sim</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/transfe...</td>\n",
       "      <td>4f32564a-0503-4a8f-91ca-c980a7636d15</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>arsenal-news-transfer-everton-berge-10639315</td>\n",
       "      <td>nationals-2</td>\n",
       "      <td>nationals-10639315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10638305</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:vid|bc:readmore:readmore:readmore</td>\n",
       "      <td>nationals</td>\n",
       "      <td>4</td>\n",
       "      <td>http://www.dailyrecord.co.uk/news/uk-world-new...</td>\n",
       "      <td>ddb98cc7-086f-4fe0-8406-9eb0072324e4</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "      <td>www.dailyrecord.co.uk</td>\n",
       "      <td>heartbreaking-reason-dogs-being-deployed-10638305</td>\n",
       "      <td>nationals-4</td>\n",
       "      <td>nationals-10638305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10636511</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:readmore:poll|sim:vid|bc</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/news/ar...</td>\n",
       "      <td>b3d3e81b-c8c2-4533-a4a4-cea2892873e9</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>arsenal-news-alexis-sanchez-ozil-10636511</td>\n",
       "      <td>nationals-2</td>\n",
       "      <td>nationals-10636511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4388389</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:vid|bc:poll|sim</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/ampp3d/cats-9-liv...</td>\n",
       "      <td>876dca7b-d04f-4fe6-a51e-a1f909ec32b2</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>cats-9-lives-facts-behind-4388389</td>\n",
       "      <td>nationals-2</td>\n",
       "      <td>nationals-4388389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10640509</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/uk-news/google-me...</td>\n",
       "      <td>4961660a-c1cb-400a-ae8e-127877b431a5</td>\n",
       "      <td>2017-06-18 02:31:02</td>\n",
       "      <td>www.mirror.co.uk</td>\n",
       "      <td>google-me-woman-whisked-feet-10640509</td>\n",
       "      <td>nationals-2</td>\n",
       "      <td>nationals-10640509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleId channel                                        pageType  \\\n",
       "0   10639315   sport                  article:news:readmore:poll|sim   \n",
       "1   10638305    news  article:news:vid|bc:readmore:readmore:readmore   \n",
       "2   10636511   sport  article:news:readmore:readmore:poll|sim:vid|bc   \n",
       "3    4388389    news                    article:news:vid|bc:poll|sim   \n",
       "4   10640509    news                                    article:news   \n",
       "\n",
       "    platform  publicationId  \\\n",
       "0  nationals              2   \n",
       "1  nationals              4   \n",
       "2  nationals              2   \n",
       "3  nationals              2   \n",
       "4  nationals              2   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.mirror.co.uk/sport/football/transfe...   \n",
       "1  http://www.dailyrecord.co.uk/news/uk-world-new...   \n",
       "2  http://www.mirror.co.uk/sport/football/news/ar...   \n",
       "3  http://www.mirror.co.uk/news/ampp3d/cats-9-liv...   \n",
       "4  http://www.mirror.co.uk/news/uk-news/google-me...   \n",
       "\n",
       "                                 userId           timestamp  \\\n",
       "0  4f32564a-0503-4a8f-91ca-c980a7636d15 2017-06-18 02:31:02   \n",
       "1  ddb98cc7-086f-4fe0-8406-9eb0072324e4 2017-06-18 02:31:02   \n",
       "2  b3d3e81b-c8c2-4533-a4a4-cea2892873e9 2017-06-18 02:31:02   \n",
       "3  876dca7b-d04f-4fe6-a51e-a1f909ec32b2 2017-06-18 02:31:02   \n",
       "4  4961660a-c1cb-400a-ae8e-127877b431a5 2017-06-18 02:31:02   \n",
       "\n",
       "         publicationSite                                     articleUrlName  \\\n",
       "0       www.mirror.co.uk       arsenal-news-transfer-everton-berge-10639315   \n",
       "1  www.dailyrecord.co.uk  heartbreaking-reason-dogs-being-deployed-10638305   \n",
       "2       www.mirror.co.uk          arsenal-news-alexis-sanchez-ozil-10636511   \n",
       "3       www.mirror.co.uk                  cats-9-lives-facts-behind-4388389   \n",
       "4       www.mirror.co.uk              google-me-woman-whisked-feet-10640509   \n",
       "\n",
       "  uniquePublicationId     uniqueArticleId  \n",
       "0         nationals-2  nationals-10639315  \n",
       "1         nationals-4  nationals-10638305  \n",
       "2         nationals-2  nationals-10636511  \n",
       "3         nationals-2   nationals-4388389  \n",
       "4         nationals-2  nationals-10640509  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the new columns are created\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets have a quick look at data from a different day\n",
    "pfile2 = fastparquet.ParquetFile('./data/sample-data/2017-06-16/part-00084-d05bf933-e313-4e4a-8aa2-01d8fe23de6f.snappy.parquet')\n",
    "df2 = pfile2.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>channel</th>\n",
       "      <th>pageType</th>\n",
       "      <th>platform</th>\n",
       "      <th>publicationId</th>\n",
       "      <th>url</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1887175</td>\n",
       "      <td>tv</td>\n",
       "      <td>article:news:gal</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/tv/tv-news/olivia-colm...</td>\n",
       "      <td>c3c0fefd-48d5-4197-b389-955e3ef0e15b</td>\n",
       "      <td>2017-06-16 23:49:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10636915</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:readmore:readmore</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/uk-news/woman-sue...</td>\n",
       "      <td>fdd23106-8a87-4114-aca8-dab24adfd0ea</td>\n",
       "      <td>2017-06-16 23:49:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13195705</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:readmore:readmore</td>\n",
       "      <td>regionals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.manchestereveningnews.co.uk/news/gr...</td>\n",
       "      <td>cd1424c5-c333-4672-8e51-c8842318674f</td>\n",
       "      <td>2017-06-16 23:49:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13194338</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:readmore:grid</td>\n",
       "      <td>regionals</td>\n",
       "      <td>47</td>\n",
       "      <td>http://www.glasgowlive.co.uk/news/glasgow-news...</td>\n",
       "      <td>d77f4835-ad85-443a-bbba-ab163f17cfaa</td>\n",
       "      <td>2017-06-16 23:49:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10636161</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/news/re...</td>\n",
       "      <td>e4eaa53e-758e-4c75-bb4b-1f10a3b00c73</td>\n",
       "      <td>2017-06-16 23:49:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleId channel                        pageType   platform  \\\n",
       "0    1887175      tv                article:news:gal  nationals   \n",
       "1   10636915    news  article:news:readmore:readmore  nationals   \n",
       "2   13195705    news  article:news:readmore:readmore  regionals   \n",
       "3   13194338    news      article:news:readmore:grid  regionals   \n",
       "4   10636161   sport                    article:news  nationals   \n",
       "\n",
       "   publicationId                                                url  \\\n",
       "0              2  http://www.mirror.co.uk/tv/tv-news/olivia-colm...   \n",
       "1              2  http://www.mirror.co.uk/news/uk-news/woman-sue...   \n",
       "2              2  http://www.manchestereveningnews.co.uk/news/gr...   \n",
       "3             47  http://www.glasgowlive.co.uk/news/glasgow-news...   \n",
       "4              2  http://www.mirror.co.uk/sport/football/news/re...   \n",
       "\n",
       "                                 userId           timestamp  \n",
       "0  c3c0fefd-48d5-4197-b389-955e3ef0e15b 2017-06-16 23:49:01  \n",
       "1  fdd23106-8a87-4114-aca8-dab24adfd0ea 2017-06-16 23:49:01  \n",
       "2  cd1424c5-c333-4672-8e51-c8842318674f 2017-06-16 23:49:01  \n",
       "3  d77f4835-ad85-443a-bbba-ab163f17cfaa 2017-06-16 23:49:01  \n",
       "4  e4eaa53e-758e-4c75-bb4b-1f10a3b00c73 2017-06-16 23:49:02  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yep, data doesn't have weird null values :-)\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['articleId', 'channel', 'pageType', 'platform', 'publicationId', 'url',\n",
       "       'userId', 'timestamp', 'publicationSite', 'articleUrlName',\n",
       "       'uniquePublicationId', 'uniqueArticleId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "questions I had for the data--  (most of these answered)\n",
    "- what is the pageType column? how a user reached a particle page?\n",
    "- how is publication id assigned? what is a 'normal' value? ie is there a lot of zeros etc? in which case really need to figure out how to get fastparquet to read them as strings!\n",
    "- what is 'ronionals'...?!\n",
    "- how are userIds assigned? does a real person only have 1 userId, or will different browser sesssions generate different userIds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data processing\n",
    "So I got a feel for what the data looks like, its time to put it in a database that I am \n",
    "a bit more familiar with-- a bit of googling seems to indicate that you may be able to use parquet as a sort of db\n",
    "but as I haven't used parquet at all before it seem easier to put it in a postgres db (easier to access from nodejs as well for the web app)\n",
    "\n",
    "Postgres db as opposed to mongo (which I had worked a lot with before) since mongo has issues with aggregations on a lot of data being really slow... still have to try postgres properly but it should in theory be a bit faster...\n",
    "\n",
    "so the processing work flow goes:\n",
    "- read parquet file into df\n",
    "- add extra columns (publicationSite, articleUrlName, uniquePublicationId, uniqueArticleId)\n",
    "- save to postgres (I am using the google cloud psql, again for ease of access, also interesting to try out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions I want to get from the data, visuals:\n",
    "- compare different publications do e.g. views over a week/day/hour? and is there a way to normalise the counts by e.g. number of visits divided by number of unique articles in the data (so that the larger publications don't dominated just because they have a lot more articles) -- small multiples could work nicely here\n",
    "- user journeys: are there users who go to a lot of pages, and which categories of pages are they (e.g. are there distinct group of users, so that one group tend to go to news + science and the others to e.g only sports?) maybe flow chart? or some sort of venn diagram...?\n",
    "- are there cateogories that are more popular at different times of the day? (e.g. more news visits in the morning, and tv in the evening...? could be traditional line charts, again small multiples could be useful\n",
    "- also look for -- are there certain articles or publications that have a sudden surge in views in the time period-- these anomalies could indicate something interesting going on\n",
    "- how are different publications linked by viewers? e.g. are certain publications likely to share users ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time to figure out how to connect to psql on gcloud:\n",
    "\n",
    "There are good instructions on the cloud platform as to how to set one up\n",
    "after creating the db instance and the db, \n",
    "create the table by :\n",
    "\n",
    "```CREATE TABLE publication_logs ( articleId integer, channel text, pageType text, platform text, publicationId integer, url text, userId text, timestamp timestamp, publicationSite text, articleUrlName text, uniquePublicationId varchar(80), uniqueArticleId varchar(80) );```\n",
    "\n",
    "which should let me write to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first connect to the db instance using the gcloud proxy tool:\n",
    "(https://cloud.google.com/sql/docs/postgres/connect-external-app)\n",
    "\n",
    "`./cloud_sql_proxy -instances=\"data4democracy-wwymak-explore:us-central1:publications-experiment\"=tcp:3306`\n",
    "\n",
    "this would let me connect via sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address = address='postgresql://' + config.psql_user + ':' + config.psql_password + '@localhost:3306/userlogs'\n",
    "engine = create_engine(address)\n",
    "connection = engine.raw_connection()\n",
    "cursor = connection.cursor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#create Index column to use as primary key\n",
    "# df2.reset_index(inplace=True)\n",
    "# df2.rename(columns={'index':'Index'}, inplace =True)\n",
    "\n",
    "#create the table but first drop if it already exists\n",
    "# command = '''DROP TABLE IF EXISTS localytics_app2;\n",
    "# CREATE TABLE localytics_app2\n",
    "# (\n",
    "# \"Index\" serial primary key,\n",
    "# \"Event\" text,\n",
    "# \"Day\" timestamp without time zone,\n",
    "# );'''\n",
    "# cursor.execute(command)\n",
    "# connection.commit()\n",
    "\n",
    "#stream the data using 'to_csv' and StringIO(); then use sql's 'copy_from' function\n",
    "output = io.StringIO()\n",
    "#ignore the index\n",
    "df2.to_csv(output, sep='\\t', header=False, index=False)\n",
    "#jump to start of stream\n",
    "output.seek(0)\n",
    "contents = output.getvalue()\n",
    "cur = connection.cursor()\n",
    "#null values become ''\n",
    "cur.copy_from(output, 'publication_logs', null=\"\")    \n",
    "connection.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample-data/2017-06-18/\n"
     ]
    }
   ],
   "source": [
    "# I would want to pull data from s3, parse and write to psql without having to download it all, and boto3 is convenient\n",
    "# for grabbing bucket contents,whereas s3fs is really handy for grabbing the parquet...\n",
    "\n",
    "bucket = 'dataen-interview-data-dev'\n",
    "access_key= config.aws_access_key\n",
    "secret_key= config.aws_secret_key\n",
    "\n",
    "client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")\n",
    "paginator2 = client.get_paginator('list_objects_v2')\n",
    "Prefix='sample-data/2017-06-18/'\n",
    "\n",
    "# Create a PageIterator from the Paginator\n",
    "# page_iterator2 = paginator2.paginate(Bucket=bucket, Prefix='sample-data/2017-06-18/')\n",
    "\n",
    "print(Prefix)\n",
    "page_iterator2 = paginator2.paginate(Bucket=bucket, Prefix=Prefix)\n",
    "keylist = []\n",
    "for page in page_iterator2:\n",
    "    keylist += page['Contents']\n",
    "keys_to_parse = [x['Key'] for x in keylist if x['Size'] > 0]\n",
    "\n",
    "# figured out how to parse parquet from s3:\n",
    "\n",
    "def parse_file_to_df(object_key):\n",
    "    s3 = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "    fs = s3fs.core.S3FileSystem(key=access_key, secret=secret_key)\n",
    "    s3_path2 = bucket + '/' + object_key\n",
    "    print(s3_path2)\n",
    "    all_paths_from_s3 = fs.glob(path=s3_path2)\n",
    "    myopen = s3.open\n",
    "    #use s3fs as the filesystem\n",
    "    fp_obj = fastparquet.ParquetFile(all_paths_from_s3,open_with=myopen)\n",
    "    #convert to pandas dataframe\n",
    "    df = fp_obj.to_pandas()\n",
    "    print('df conversion')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and how to write to psql on remote host\n",
    "def write_psql(df):\n",
    "    output = io.StringIO()\n",
    "    #ignore the index\n",
    "    df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "    print('to csv done')\n",
    "    #jump to start of stream\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    connection = engine.raw_connection()\n",
    "    cur = connection.cursor()\n",
    "    #null values become ''\n",
    "    print(cur)\n",
    "    cur.copy_from(output, 'publication_logs', null=\"\")\n",
    "    connection.commit()\n",
    "    cur.close()\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after testing the above, and it seems to work fine, put it in a .py file and run from the command line like so:\n",
    "`python parse-to-psql.py sample-data/2017-06-16/`\n",
    "\n",
    "I have done part of 2017-06-16, 2017-06-17, 2017-06-18, except the `copy_from` seems to take a long time and my connection to the db hung up... :(\n",
    "\n",
    "But there should be enough data in there to experiment with hopefully. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataen-interview-data-dev/sample-data/2017-06-18/part-*.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "# a previous experiment: it does work although in the middle of it python seems to be taking over my laptop's memory!\n",
    "# the writing to psql seems to take a really long time?? \n",
    "#  see if I can parse a whole day of data into a df?\n",
    "s3_path2 = bucket + '/' + 'sample-data/2017-06-18/part-*.snappy.parquet'\n",
    "print(s3_path2)\n",
    "all_paths_from_s3 = fs.glob(path=s3_path2)\n",
    "\n",
    "myopen = s3.open\n",
    "#use s3fs as the filesystem\n",
    "fp_obj = fastparquet.ParquetFile(all_paths_from_s3,open_with=myopen)\n",
    "#convert to pandas dataframe\n",
    "df_remote_2 = fp_obj.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6580063, 8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remote_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>channel</th>\n",
       "      <th>pageType</th>\n",
       "      <th>platform</th>\n",
       "      <th>publicationId</th>\n",
       "      <th>url</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6580058</th>\n",
       "      <td>13197469</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:vid|bc:readmore:readmore:readmore</td>\n",
       "      <td>regionals</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.birminghammail.co.uk/news/midlands-...</td>\n",
       "      <td>57a6d9f3-421e-4a78-879d-99ce8944a4b7</td>\n",
       "      <td>2017-06-18 03:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580059</th>\n",
       "      <td>10639465</td>\n",
       "      <td>news</td>\n",
       "      <td>article:news:readmore:readmore</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/news/real-life-stories...</td>\n",
       "      <td>4c7eb64b-cead-460d-be97-0e48e3df56c0</td>\n",
       "      <td>2017-06-18 03:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580060</th>\n",
       "      <td>10638932</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:vid|bc:readmore:readmore:readmore...</td>\n",
       "      <td>nationals</td>\n",
       "      <td>4</td>\n",
       "      <td>http://www.dailyrecord.co.uk/sport/football/fo...</td>\n",
       "      <td>71435f93-a1ab-465b-9497-2b18a2c161a2</td>\n",
       "      <td>2017-06-18 03:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580061</th>\n",
       "      <td>13199066</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:readmore</td>\n",
       "      <td>regionals</td>\n",
       "      <td>16</td>\n",
       "      <td>http://www.liverpoolecho.co.uk/sport/football/...</td>\n",
       "      <td>c19393ca-8e17-4cdc-aa3d-cbba6156bd45</td>\n",
       "      <td>2017-06-18 03:19:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580062</th>\n",
       "      <td>10640100</td>\n",
       "      <td>sport</td>\n",
       "      <td>article:news:readmore:vid|bc:poll|sim</td>\n",
       "      <td>nationals</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.mirror.co.uk/sport/football/news/re...</td>\n",
       "      <td>8dbb9ef2-7ad8-41de-a0b2-67f90b1bd5e3</td>\n",
       "      <td>2017-06-18 03:19:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         articleId channel                                           pageType  \\\n",
       "6580058   13197469    news     article:news:vid|bc:readmore:readmore:readmore   \n",
       "6580059   10639465    news                     article:news:readmore:readmore   \n",
       "6580060   10638932   sport  article:news:vid|bc:readmore:readmore:readmore...   \n",
       "6580061   13199066   sport                     article:news:readmore:readmore   \n",
       "6580062   10640100   sport              article:news:readmore:vid|bc:poll|sim   \n",
       "\n",
       "          platform  publicationId  \\\n",
       "6580058  regionals              1   \n",
       "6580059  nationals              2   \n",
       "6580060  nationals              4   \n",
       "6580061  regionals             16   \n",
       "6580062  nationals              2   \n",
       "\n",
       "                                                       url  \\\n",
       "6580058  http://www.birminghammail.co.uk/news/midlands-...   \n",
       "6580059  http://www.mirror.co.uk/news/real-life-stories...   \n",
       "6580060  http://www.dailyrecord.co.uk/sport/football/fo...   \n",
       "6580061  http://www.liverpoolecho.co.uk/sport/football/...   \n",
       "6580062  http://www.mirror.co.uk/sport/football/news/re...   \n",
       "\n",
       "                                       userId           timestamp  \n",
       "6580058  57a6d9f3-421e-4a78-879d-99ce8944a4b7 2017-06-18 03:19:00  \n",
       "6580059  4c7eb64b-cead-460d-be97-0e48e3df56c0 2017-06-18 03:19:00  \n",
       "6580060  71435f93-a1ab-465b-9497-2b18a2c161a2 2017-06-18 03:19:00  \n",
       "6580061  c19393ca-8e17-4cdc-aa3d-cbba6156bd45 2017-06-18 03:19:01  \n",
       "6580062  8dbb9ef2-7ad8-41de-a0b2-67f90b1bd5e3 2017-06-18 03:19:01  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remote_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
